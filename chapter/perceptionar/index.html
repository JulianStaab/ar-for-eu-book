<!DOCTYPE HTML>
<!--
Prologue by HTML5 UP
html5up.net | @ajlkn
Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
Jekyll integration by Chris Bobbe | chrisbobbe.github.io
-->
<html><head><!-- Robots -->
  <meta name="robots" content="index, follow" /><link rel="canonical" href="https://codereality.net/ar-for-eu-book/chapter/perceptionar/" /><!-- Title, description, author --><title>Perceptual Foundations of Augmented Reality  (started) | The Open Augmented Reality Teaching Book - Create and Code Augmented Reality!</title>
  <meta name="description" content="This is the demo site for a Jekyll theme version of HTML5 UP&#39;s sleek, responsive site template Prologue." />
  <meta name="author" content="Ralf Klamma" />
  
  <!-- Open Graph -->
  <meta property="og:title" content="Perceptual Foundations of Augmented Reality  (started) | The Open Augmented Reality Teaching Book - Create and Code Augmented Reality!" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="https://codereality.net/ar-for-eu-book/assets/images/avatar.png" />
  <meta property="og:url" content="https://codereality.net/ar-for-eu-book/chapter/perceptionar/" />
  <meta property="og:site_name" content="The Open Augmented Reality Teaching Book" />
  <meta property="og:description" content="This is the demo site for a Jekyll theme version of HTML5 UP&#39;s sleek, responsive site template Prologue." />
  
  <!-- Styles -->
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <!--[if lte IE 8]><script src="/ar-for-eu-book/assets/js/ie/html5shiv.js" defer></script><![endif]-->
  <link rel="stylesheet" href="/ar-for-eu-book/assets/css/main.css" />
  <!--[if lte IE 8]><link rel="stylesheet" href="/ar-for-eu-book/assets/css/ie8.css" /><![endif]-->
  <!--[if lte IE 9]><link rel="stylesheet" href="/ar-for-eu-book/assets/css/ie9.css" /><![endif]-->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css">

  <!-- Scripts -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js" defer></script>
  <script src="/ar-for-eu-book/assets/js/jquery.scrolly.min.js" defer></script>
  <script src="/ar-for-eu-book/assets/js/jquery.scrollzer.min.js" defer></script>
  <script src="/ar-for-eu-book/assets/js/skel.min.js" defer></script>
  <script src="/ar-for-eu-book/assets/js/util.js" defer></script>
  <!--[if lte IE 8]><script src="/ar-for-eu-book/assets/js/ie/respond.min.js" defer></script><![endif]-->
  <script src="/ar-for-eu-book/assets/js/main.js" defer></script>

</head><body><!-- Header -->
<div id="header">
  <div class="top"><!-- Logo -->
<div id="logo">
  <a href="https://codereality.net/ar-for-eu-book/" id="home-link">
    <span class="image avatar48"><img src="/ar-for-eu-book/assets/images/avatar.png" alt="Avatar of Ralf Klamma" /></span>
    <h1 id="title">The Open Augmented Reality Teaching Book</h1>
    <p>Create and Code Augmented Reality!</p>
  </a>
</div><!-- Nav -->
<nav id="nav">
  <ul><li><a href="/ar-for-eu-book/" id="welcome-link">
            <span class="icon fa-home">Welcome</span>
          </a></li><li><a href="/ar-for-eu-book/blog.html" id="blog-posts-link">
            <span class="icon fa-pen">Blog Posts</span>
          </a></li><li><a href="/ar-for-eu-book/toc/" id="table-of-contents-link">
            <span class="icon fa-book-open">Table of Contents</span>
          </a></li><li><a href="/ar-for-eu-book/bibliography.html" id="bibliography-link">
            <span class="icon fa-bookmark">Bibliography</span>
          </a></li><li><a href="/ar-for-eu-book/contributors.html" id="contributors-link">
            <span class="icon fa-user-edit">Contributors</span>
          </a></li><li><a href="/ar-for-eu-book/about/" id="about-the-book-link">
            <span class="icon fa-info-circle">About the book</span>
          </a></li></ul>
</nav></div>
  <div class="bottom"><!-- Social Icons -->
<ul class="icons"><li><a href="https://twitter.com/AR_FOR_EU" class="icon-b fa-twitter"><span class="label">Twitter</span></a></li><li><a href="https://www.facebook.com/AR.FOR.EU/" class="icon-b fa-facebook-f"><span class="label">Facebook</span></a></li><li><a href="https://github.com/klamma/ar-for-eu-book" class="icon-b fa-github"><span class="label">GitHub</span></a></li><li><a href="https://codereality.net/ar-for-eu-book/feed.xml" class="fas fa-rss-square"><span class="label"></span></a></li><li><a href="mailto:klamma@dbis.rwth-aachen.de" class="icon fa-envelope"><span class="label">Email</span></a></li></ul>
</div>
</div>
<!-- Main -->
<div id="main">
	<!-- Page -->
	<article class="shade-two">
	  <div class="container">
			<header>
				<h2><img src="../../assets/images/ReadingChapter.png" style="align:right; width: 13%; height: 13%; vertical-align:middle">&nbsp;&nbsp;Perceptual Foundations of Augmented Reality  (started)</h2></header>
<h1 id="perceptual-foundations-of-augmented-reality">Perceptual Foundations of Augmented Reality</h1>

<p>Definition Perception: The top-down way our brains organize and interpret information and put it into context.</p>

<p>Definition Sensation: The bottom-up process by which our sense, like vision, hearing and touch, receive and relay outside stimuli.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.1%20Definition%20Sensation.JPG" style="align:left; width: 60%; height: 60%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.1</figcaption>
</figure>

<h2 id="visual-perception">Visual Perception</h2>

<h4 id="what-is-perception">What is perception?</h4>

<p>Perception consists from three main processes called recognition, organizing, and interpreting. Recognition happens basically everyday, we are aware of everything, such as sounds, lights, and colors. Then you are organizing everything that you perceive.  Interpretation refers to the process by which we represent and understand stimuli that affect us.</p>

<p>Recognizing + Organizing+ Interpreting = Sensory Information</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.2%20perception.JPG" style="align:left; width: 60%; height: 60%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.2</figcaption>
</figure>

<h4 id="what-is-visual-perception">What is visual perception?</h4>

<p>Visual perception is the end of product of vision.</p>

<p>“Perception is not something that happens to us, or in us. It is something we do…
Vision is a mode of exploration of the environment drawing on implicit understanding 
of sensorimotor regularities”</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.3%20Visual%20perception.jpg" style="align:left; width: 60%; height: 60%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.3</figcaption>
</figure>

<h4 id="how-vision-works">How vision works?</h4>

<p>The eye passes through the cornea, and go down to the iris. The light reflects and sort of vision is also a chemical reaction.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.4%20vision.JPG" style="align:left; width: 60%; height: 60%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.4</figcaption>
</figure>

<h4 id="preattentive-features">Preattentive features</h4>

<p>Vision helps us to understand the distinctive features of the environment.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.5%20Preattentive%20features.JPG" style="align:left; width: 60%; height: 60%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.5</figcaption>
</figure>

<h3 id="gestalt-theory">Gestalt Theory</h3>

<figure>
    <img src="../../assets/figures/perception_ar/No.6%20Gestalt%20Theory.JPG" style="align:left; width: 60%; height: 60%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.6</figcaption>
</figure>

<p><strong>Figure and Ground</strong> explains how we put different elements together to make one scene or a whole image.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.7%20Figure%20and%20Ground.jpg" style="align:left; width: 40%; height: 40%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.7</figcaption>
</figure>

<p><strong>Similarity</strong> States that things which share visual characteristics such as shape, size, colour, texture, value or orientation will be seen as belonging together.</p>

<p>States that things which share visual characteristics such as shape, size, colour, texture, value or orientation will be seen as belonging together.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.8%20Similarity.jpg" style="align:left; width: 40%; height: 40%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.8</figcaption>
</figure>

<p><strong>Proximity</strong> Elements tend to be perceived as aggregated into group if they are near each other. other.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.9%20Proximity.jpg" style="align:left; width: 40%; height: 40%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.9</figcaption>
</figure>

<p><strong>Common Fate</strong>: Objects which are facing the same direction or appear to be travelling in the same direction are usually grouped together.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.10%20Common%20Fate.jpg" style="align:left; width: 40%; height: 40%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.10</figcaption>
</figure>

<p><strong>Continuity</strong>: in order to fill in missing data we often see things as continuous or whole.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.11%20Continuity.jpg" style="align:left; width: 40%; height: 40%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.11</figcaption>
</figure>

<p><strong>Closure</strong>: If we have a large pattern with missing components we tend to fill in the missing parts to create the image we actually see.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.12%20Closure.jpg" style="align:left; width: 40%; height: 40%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.12</figcaption>
</figure>

<p><strong>Area</strong>: When areas are overlapping, the smallest area is seen as the figure and the larger is the ground. When we look at this object we see this as one object on top of another instead of a hole in the larger area.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.13%20Area.JPG" style="align:left; width: 40%; height: 40%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.13</figcaption>
</figure>

<p><strong>Symmetry</strong>: We tend to organize complex objects into a whole, we are more likely to group symmetrical objects.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.14%20Symmetry.jpg" style="align:left; width: 40%; height: 40%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.14</figcaption>
</figure>

<p><strong>Vergence-accommodation conflict</strong>: There is a disparity between the physical surface of the screen – accommodation - and the focal point of the simulated world you’re staring at - vergence.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.15%20Vergence-accommodation%20conflict.jpg" style="align:left; width: 60%; height: 60%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.15</figcaption>
</figure>

<h2 id="spatial-audio">Spatial Audio</h2>

<p>Detecting a weak sensory signal like a random clap in daily life isn’t only about the strength of the 
stimulus. It is also about the psychological state, your alertness and expectations in the moment.</p>

<h4 id="signal-detection-theory-a-model-for-predicting-how-and-when-a-person-will-detect-weak-stimuli-partly-based-on-a-context"><strong>SIGNAL DETECTION THEORY</strong>: a model for predicting how and when a person will detect weak stimuli, partly based on a context.</h4>

<p>Our hearing is adjusted by our preferences by our personal perceptions that is valuable for us.</p>

<p>The paranoid parent’s brains are so trained on their baby, it gives their senses a sort of boosted 
ability, but only in relation to the subject of their attention.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.16%20Spatial%20Audio.jpg" style="align:left; width: 60%; height: 60%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.16</figcaption>
</figure>

<h2 id="touch">Touch</h2>

<h4 id="proprioception">PROPRIOCEPTION</h4>

<p>Proprioception us the perception of the world  with our body, so how perceive and understand things around us.  our perception embodied and active when we see, we are ready touch, and we tend to visualize our path to the object. Our body experienced all directions of  the environment, we understand the space in 3D. For example, when we see something that we need to grab, we will understand it is a shape.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.17%20Touch.jpg" style="align:left; width: 40%; height: 40%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.17</figcaption>
</figure>

<h2 id="ui">UI</h2>

<p>UX (User experience) and UI (User interface) is different. <strong>UI</strong> can deal with traditional concepts like visual design elements such as colors and typography. <strong>UX</strong> is all below user interface. User experience design is a human-first way of designing products. Don Norman, a cognitive scientist and co-founder of the Nielsen Norman Group Design Consultancy, is credited with coining the term “user experience.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.18(1)%20UI.jpg" style="align:left; width: 60%; height: 60%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.18(1)</figcaption>
</figure>

<p>Today UI design is mainly focused on the 2D screens. We are living in 2D world , everyone has a phone, and we use to all references to understand what the camera means, what is this icon.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.18(2)%20UI.JPG" style="align:left; width: 100%; height: 100%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.18(2)</figcaption>
</figure>

<p><strong>However,</strong> AR (Augmented Reality) points to use all the sense to move away from the screen. In the 60s, the person called Douglas Engelbart, he invented the modern mouse, but the aspect of that not invent something that will constantly use, it was about inventing augment human intelligence that could help us to experience our world in more senses. He wrote articiles about augmenting human intelligence in using all senses that we use our bodies, speech to work with technology.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.18(3)%20UI.JPG" style="align:left; width: 100%; height: 100%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.18(3)</figcaption>
</figure>

<p>In 1968, Ivan Sutherland who is very famous founder of VR and MR, he said “if the task of the display is to serve as a looking glass into the mathematical wonderland constructed in computer memory, it should serve as many senses as possible”</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.18(4)%20UI.gif" style="align:left; width: 60%; height: 60%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.18(4)</figcaption>
</figure>

<p>In terms of the spatial holograms and spatial interactions, it shows that objects are really realistic that we can work with.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.18(5)%20UI.jpg" style="align:left; width: 60%; height: 60%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.18(5)</figcaption>
</figure>

<h4 id="affordances">Affordances</h4>

<p>Affordances are the possible actions. Donald Norman (1988) said “possibilities for action that are readily perceivable by individuals”. He invented the storm and created the notion of affordances that means projects represent their functions at 3D world.</p>

<h4 id="ui-in-ar">UI in AR</h4>

<p>The lateral field of human view is about 140 degrees, but with the peripheral visual is 200-220 degrees compared to peripheral vision of the body. We need to follow the natural ways of perception, and don’t put objects on the back bunny.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.19(1)%20Affordances.jpg" style="align:left; width: 60%; height: 60%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.19(1)</figcaption>
</figure>

<h4 id="the-hierarchy-of-needs-in-ar">The Hierarchy of Needs in AR</h4>

<figure>
    <img src="../../assets/figures/perception_ar/No.19(2)%20Affordances.JPG" style="align:left; width: 60%; height: 60%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.19(2)</figcaption>
</figure>

<h4 id="immersion-and-exploration">Immersion and exploration</h4>

<p>•user is the center of the environment</p>

<p>•users will want to try their own ideas</p>

<p>• scale makes a huge impact on presence</p>

<p>• small details matter</p>

<h4 id="attention">Attention</h4>

<p>•users have freedom to look anywhere, so capturing and guiding attention is important</p>

<p>•audio and visual cues help nudge users in the right way</p>

<p>•forced attention – not always a good idea</p>

<h4 id="ui-toolbox">UI TOOLBOX</h4>

<figure>
    <img src="../../assets/figures/perception_ar/No.20(1)%20UI%20TOOLBOX.JPG" style="align:left; width: 100%; height: 100%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.20(1)</figcaption>
</figure>

<p>We use our gaze (vision) as the way we see things around; we use gaze cursor as the metaphor of the mouse cursor on the computer; Voice can activate different voice commands; We can use spatial audio as 3D emergent audio (an immersion sound) to guide people to show how sounds moved where an object is located by positioning 3D sound in different places; Gestures is how we can use gaze to activate and trigger with these holograms.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.20(2)%20UI%20TOOLBOX.jpg" style="align:left; width: 80%; height: 80%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.20(2)</figcaption>
</figure>

<p>Note: when you create UI, you need to know:</p>

<p>•Ergonomics</p>

<p>•Safety guidelines for the content</p>

<p>• Clicker, laser pointer</p>

<p>•Other people and their voice commands</p>

<p><strong>Text</strong></p>

<p>— avoid large amounts of text to instruct of inform users with information within an augmented environment</p>

<p>— consider how you will draw attention to text within your environment to capture the user’s attention</p>

<p><strong>Colours</strong></p>

<p>— Shadows and lighting may change the way colour appears on objects and make things.</p>

<p>— By modifying the <strong>saturation</strong> and <strong>brightness</strong> of a single hue, you can generate <strong>multiple colours</strong>— darks, lights, backgrounds, accents, eye-catchers— but it’s not overwhelming on the eye.</p>

<p>— darker colours tend to carry more visual weight, and these kinds of elements need to be balanced out with lighter colours.</p>

<p><strong>The shade of the center dot is the same in all the squares</strong></p>

<p>The shade of the background influences how we perceive it. All squares are uniformly shaded, but each square lighter on its left edge than on its right edge.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.21%20shade.jpg" style="align:left; width: 80%; height: 80%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.21</figcaption>
</figure>

<h3 id="storytelling">Storytelling</h3>

<p>Storytelling comes from writers, it can be histories, stories of legends.</p>

<h4 id="storyboarding">Storyboarding</h4>

<p>Storyboard is the collection of the shots of the images for movies that will be created.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.22(1)%20Storyboarding.JPG" style="align:left; width: 80%; height: 80%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.22(1)</figcaption>
</figure>

<p>But in 3D,  the simplest way is to go to the 3D modelling application, such as Unity, Maya, and Cinema 4D, to create a story using prefabs, the 3D models of objects, and explain what is going to happen with the launch examination, and how the user is going to interact with objects.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.22(2)%20Storyboarding.jpg" style="align:left; width: 80%; height: 80%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.22(2)</figcaption>
</figure>

<h3 id="map-your-story">Map your story</h3>

<p>This will be an inherently interdisciplinary endeavour, and it will need contributions from designers, data engineers and visualizers, brain scientists, 3D programmers, mechanical engineers, materials scientists, artists, storytellers, and others.</p>

<h3 id="uncanny-valley">Uncanny Valley</h3>

<p>You need to find that level of the character that will work in AR, and also try to find the balance between how real your character is going to be, and how empathic you want to person feels of that character. Don’t fall down about your character.</p>

<figure>
    <img src="../../assets/figures/perception_ar/No.22(3)%20Storyboarding.jpg" style="align:left; width: 60%; height: 60%; border: 15px solid;
  border-image-slice: 1;
  border-width: 10px; border-image-source: linear-gradient(to left, #0092b6, #154676);" alt="" />
    <figcaption>Image of No.22(3)</figcaption>
</figure>

<h3 id="summary">Summary</h3>

<p>AR UI is quite different from the traditional UI and requires new ways of approaching 
the challenge of informing and empowering users.</p>
</article>
</div><!-- Footer -->
<div id="footer">
  
  <!-- Copyright -->
  <ul class="copyright">
    
      <li>&copy;The Open Augmented Reality Teaching Book. All rights reserved.</li>
    
  </ul>
  
</div></body>
</html>